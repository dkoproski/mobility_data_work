---
title: "Code - A bit more organized"
author: "Dylan Koproski"
date: "2025-01-28"
output: pdf_document
---
# Libraries






## Category definitions

```{r}
all_cat = c(
  "Accounting, Tax Preparation, Bookkeeping, and Payroll Services",
  "Activities Related to Credit Intermediation",
  "Activities Related to Real Estate",
  "Advertising, Public Relations, and Related Services",
  "Agencies, Brokerages, and Other Insurance Related Activities",
  "Architectural, Engineering, and Related Services",
  "Automotive Parts, Accessories, and Tire Stores",
  "Automotive Repair and Maintenance",
  "Bakeries and Tortilla Manufacturing",
  "Beer, Wine, and Liquor Stores",
  "Book Stores and News Dealers",
  "Building Equipment Contractors",
  "Building Finishing Contractors",
  "Building Material and Supplies Dealers",
  "Child Day Care Services",
  "Clothing Stores",
  "Consumer Goods Rental",
  "Couriers and Express Delivery Services",
  "Depository Credit Intermediation",
  "Drinking Places (Alcoholic Beverages)",
  "Drycleaning and Laundry Services",
  "Electronic and Precision Equipment Repair and Maintenance",
  "Electronics and Appliance Stores",
  "Elementary and Secondary Schools",
  "Florists",
  "Furniture Stores",
  "Gasoline Stations",
  "General Medical and Surgical Hospitals",
  "General Merchandise Stores, including Warehouse Clubs and Supercenters",
  "Glass and Glass Product Manufacturing",
  "Grocery Stores",
  "Health and Personal Care Stores",
  "Home Furnishings Stores",
  "Investigation and Security Services",
  "Jewelry, Luggage, and Leather Goods Stores",
  "Justice, Public Order, and Safety Activities",
  "Legal Services",
  "Machinery, Equipment, and Supplies Merchant Wholesalers",
  "Museums, Historical Sites, and Similar Institutions",
  "Offices of Dentists",
  "Offices of Other Health Practitioners",
  "Offices of Physicians",
  "Offices of Real Estate Agents and Brokers",
  "Other Amusement and Recreation Industries",
  "Other Financial Investment Activities",
  "Other Miscellaneous Manufacturing",
  "Other Miscellaneous Store Retailers",
  "Other Personal Services",
  "Other Professional, Scientific, and Technical Services",
  "Other Schools and Instruction",
  "Other Specialty Trade Contractors",
  "Personal and Household Goods Repair and Maintenance",
  "Personal Care Services",
  "Printing and Related Support Activities",
  "Promoters of Performing Arts, Sports, and Similar Events",
  "Radio and Television Broadcasting",
  "Religious Organizations",
  "Restaurants and Other Eating Places",
  "Shoe Stores",
  "Sound Recording Industries",
  "Special Food Services",
  "Specialized Design Services",
  "Specialty (except Psychiatric and Substance Abuse) Hospitals",
  "Specialty Food Stores",
  "Sporting Goods, Hobby, and Musical Instrument Stores",
  "Support Activities for Road Transportation",
  "Technical and Trade Schools",
  "Transit and Ground Passenger Transportation",
  "Traveler Accommodation",
  "Warehousing and Storage",
  "Wired and Wireless Telecommunications Carriers"
)

medical_services = c(
  "General Medical and Surgical Hospitals",
  "Health and Personal Care Stores",
  "Offices of Dentists",
  "Offices of Other Health Practitioners",
  "Specialty (except Psychiatric and Substance Abuse) Hospitals",
  "Offices of Physicians"
)

essential_services = c(
  "Health and Personal Care Stores",
  "Pharmacies and Drug Stores",
  "Grocery Stores",
  "Gasoline Stations",
  "Depository Credit Intermediation",
  "Public Transport Hubs",
  "Government Offices"
)

retail_shopping = c(
  "General Merchandise Stores, including Warehouse Clubs and Supercenters",
  "Clothing Stores",
  "Shoe Stores",
  "Jewelry, Luggage, and Leather Goods Stores",
  "Electronics and Appliance Stores",
  "Furniture Stores",
  "Home Furnishings Stores",
  "Specialty Food Stores",
  "Sporting Goods, Hobby, and Musical Instrument Stores",
  "Book Stores and News Dealers"
)

entertainment_recreation = c(
  "Other Amusement and Recreation Industries",
  "Museums, Historical Sites, and Similar Institutions",
  "Promoters of Performing Arts, Sports, and Similar Events",
  "Radio and Television Broadcasting",
  "Sound Recording Industries"
)

personal_services = c(
  "Personal Care Services",
  "Drycleaning and Laundry Services",
  "Other Personal Services",
  "Personal and Household Goods Repair and Maintenance"
)

hospitality_lodging = c(
  "Traveler Accommodation",
  "Bed and Breakfast Inns",
  "Resorts",
  "Extended Stay Hotels"
)

office_professional = c(
  "Accounting, Tax Preparation, Bookkeeping, and Payroll Services",
  "Legal Services",
  "Architectural, Engineering, and Related Services",
  "Agencies, Brokerages, and Other Insurance Related Activities",
  "Offices of Physicians",
  "Offices of Dentists",
  "Offices of Other Health Practitioners",
  "Real Estate Agencies"
)


target_categories = c("Drinking Places (Alcoholic Beverages)", "Restaurants and Other Eating Places", "Beer, Wine, and Liquor Stores")

df_long_model_filtered_1 = df_long |> 
  mutate(non_restaurant = if_else(top_category %in% target_categories, "No", "Yes"))
```

# Exploratory Data Analysis (EDA)

## Zip Code Flow Matrix
```{r}
# Remove rows with NA in visitor_zip or poi_zip
zip_matrix = final_df |> 
  filter(!is.na(visitor_zip) & !is.na(poi_zip)) |> 
  group_by(visitor_zip, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) |> 
  pivot_wider(names_from = poi_zip, values_from = total_visitors, values_fill = 0)
```
```{r, eval = FALSE}
# Convert to matrix and plot
zip_matrix_plot = zip_matrix |> 
  column_to_rownames("visitor_zip") |> 
  as.matrix() |> 
  heatmap(
    col = colorRampPalette(c("white", "red"))(100),
    scale = "none",
    main = "Zip-to-Zip Visitor Flow",
    xlab = "Destination ZIP (To)",
    ylab = "Origin ZIP (From)"
  )
```

## State to Destination ZIP in NYC
```{r}
final_df_with_state = final_df |> 
  left_join(df_tract_zip, by = c("visitor_zip" = "zip")) |> 
  select(!zip) |> 
  rename(visitor_state = usps_zip_pref_state)

state_zip_matrix = final_df_with_state |> 
  group_by(visitor_state, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 

ggplot(state_zip_matrix, aes(x = poi_zip, y = visitor_state, fill = total_visitors)) + 
  geom_tile() + 
  scale_fill_viridis_c() + 
  labs(
    title = "State-to-NYC ZIP Code Visitor Flow",
    x = "Destination ZIP (NYC)",
    y = "Origin State"
  ) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```


```{r, eval = FALSE}
nyc_zip_visitors = final_df |> 
  group_by(poi_long, poi_lat) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 


ggplot(nyc_zip_visitors, aes(x = poi_long, y = poi_lat)) +
  stat_density_2d(aes(fill = after_stat(level)), geom = "polygon", color = NA) +
  scale_fill_viridis_c() +
  labs(
    title = "Heatmap of NYC POIs by Visitor Counts",
    x = "Longitude", 
    y = "Latitude"
  ) +
  theme_minimal()
```

## Flow map - work in progress

```{r}
#excise visitors from hawaii, include the second filter argument to get a better look at lower ends of data
flow_df = final_df |> 
  filter(vis_long > -150) |> 
  filter(poi_long > -150) |> 
  filter(vis_lat < 60) |> 
  filter(poi_lat < 50) |> 
  left_join(df_tract_zip, by = c("visitor_zip" = "zip"), multiple = "any") |> 
  select(!zip) |> 
  rename(visitor_state = usps_zip_pref_state) |> 
  left_join(df_tract_zip, by = c("poi_zip" = "zip"), multiple = "any") |> 
  rename(poi_state = usps_zip_pref_state) |> filter(poi_state == "TN")

# if you want to include visitors from hawaii
# flow_df = final_df

usa = map_data("state")

usa = rename(usa, state = "region")

usa$state = str_to_title(usa$state)

stateData = usa |> 
  arrange(state, group, order)

ggplot() +
  geom_polygon(data = stateData,
               aes(x = long, y = lat, group = group),
               fill = "white", color = "gray50") +
  
  geom_segment(data = flow_df,
               aes(x = vis_long, y = vis_lat,
                   xend = poi_long, yend = poi_lat,
                   color = total_visitors),
               alpha = 0.6, linewidth = 1) +
  scale_color_fermenter(name = "Total Visitors", direction = -1) +
  coord_map() +
  theme_minimal() +
  labs(color = "Volume of Visits",
       title = "Zip Code to Zip Code Visits",
       x = "Longitude",
       y = "Latitude")


```

## Visitor counts

```{r}
state_visitors = final_df_with_state |> 
 # filter(visitor_state != "NY") |> 
#  filter(visitor_state != "NJ") |> 
  group_by(visitor_state) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) |> 
  arrange(desc(total_visitors))

ggplot(state_visitors, aes(x = reorder(visitor_state, -total_visitors), y = total_visitors)) +
  geom_col(fill = "steelblue") +
  labs(
    title = "Total Visitors by State",
    x = "State",
    y = "Total Visitors"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Map view of visitor counts

```{r}
# Aggregate visitor counts by state
state_visitors_map = final_df_with_state |> 
  group_by(visitor_state) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) |> 
  filter(!is.na(visitor_state)) |> 
  mutate(log_visitors = log1p(total_visitors)) |> 
  rename(state = visitor_state)

# Plot using log scale
plot_usmap(data = state_visitors_map, regions = "states", values = "log_visitors") +
  scale_fill_viridis_c(name = "Log Visitors", option = "magma") +
  labs(title = "Log-Scaled Visitor Counts by State") +
  theme_minimal()

```

```{r}
# Function to create bar plots for each category
plot_age_group_counts = function(df, category_name, category_vector) {
  df_filtered = df |> 
    filter(top_category %in% category_vector) |> 
    group_by(age_group) |> 
    summarize(total_visitors = sum(visitor_count, na.rm = TRUE), .groups = "drop")
  
  ggplot(df_filtered, aes(x = age_group, y = total_visitors)) +
    geom_col(fill = "steelblue") +
    labs(
      title = paste("Visitor Counts by Age Group -", category_name),
      x = "Age Group",
      y = "Total Visitors"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5),
      legend.position = "none"  # Remove legend
    )
}

# Generate bar plots for each category
plot_age_group_counts(df_long, "All", all_cat)
plot_age_group_counts(df_long, "Healthcare", medical_services)
plot_age_group_counts(df_long, "Essential Services", essential_services)
plot_age_group_counts(df_long, "Retail Shopping", retail_shopping)
plot_age_group_counts(df_long, "Entertainment/Recreation", entertainment_recreation)
plot_age_group_counts(df_long, "Personal Services", personal_services)
plot_age_group_counts(df_long, "Hospitality/Lodging", hospitality_lodging)
plot_age_group_counts(df_long, "Office/Professional", office_professional)
plot_age_group_counts(df_long, "Restaurant/Bar", target_categories)

```

```{r}
# Aggregate visitor counts by age group and POI category
df_filtered = df_long |> 
  mutate(category_group = case_when(
    top_category %in% medical_services ~ "Healthcare",
    top_category %in% essential_services ~ "Essential Services",
    top_category %in% retail_shopping ~ "Retail Shopping",
    top_category %in% entertainment_recreation ~ "Entertainment/Recreation",
    top_category %in% personal_services ~ "Personal Services",
    top_category %in% hospitality_lodging ~ "Hospitality/Lodging",
    top_category %in% office_professional ~ "Office/Professional",
    top_category %in% target_categories ~ "Restaurant/Bar",
    TRUE ~ "Other"
  )) |> 
  filter(category_group != "Other") |>  # Exclude any unintended categories
  group_by(category_group, age_group) |> 
  summarize(total_visitors = sum(visitor_count, na.rm = TRUE), .groups = "drop")

# Create stacked bar plot
ggplot(df_filtered, aes(x = category_group, y = total_visitors, fill = age_group)) +
  geom_col(position = "stack") +
  labs(
    title = "Visitor Counts by POI Category and Age Group",
    x = "POI Category",
    y = "Total Visitors",
    fill = "Age Group"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability
    legend.position = "right"  # Keep legend for age group colors
  )

```


## Pie chart (alternative to above)

```{r}
age_group_proportions = df_long_model_filtered_1 |>
  group_by(age_group) |>
  summarize(total_visitors = sum(visitor_count), .groups = "drop") |>
  mutate(proportion = total_visitors / sum(total_visitors))

ggplot(age_group_proportions, aes(x = "", y = proportion, fill = age_group)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Proportion of Visitors by Age Group",
    fill = "Age Group"
  ) +
  theme_void()

```


## Density Plot

```{r, eval = FALSE}
ggplot(df_long_model_filtered_1, aes(x = visitor_count, fill = age_group)) +
  geom_density(alpha = 0.6) +
  labs(
    title = "Density of Visitor Counts by Age Group",
    x = "Visitor Count",
    y = "Density",
    fill = "Age Group"
  ) +
  theme_minimal()
```

# Modeling



## All categories vs. categories of interest

```{r}
df_long_model_filtered_1 = df_long |> 
  mutate(non_restaurant = if_else(top_category %in% target_categories, "No", "Yes"))

poisson_model_interact_1 = glm(visitor_count ~ age_group * non_restaurant, family = poisson(link = "log"), data = df_long_model_filtered_1)
summary(poisson_model_interact_1)

dispersion_test = sum(residuals(poisson_model_interact_1, type = "pearson")^2) / poisson_model_interact_1$df.residual
print(dispersion_test)

#Overdispersion present, use NB

```


## NB models, overdispersion was present
### NB model on whole data
"Are older individuals visiting restaurants/bars at lower rates compared to other age groups?"
A negative estimate implies that an age group is visiting a location at a lower rate than the reference
```{r}
nb_whole = glm.nb(visitor_count ~ age_group, data = df_long)
summary(nb_whole)


df_model_filtered = df_long |> 
  filter(top_category %in% target_categories)

nb_rest = glm.nb(visitor_count ~ age_group, data = df_model_filtered)
summary(nb_rest)
```


### NB with interaction - not necessary

```{r, eval = FALSE}
run_nb_model = function(df, category_name, category_vector, reference_name, target_categories) {
  df_model = df |> 
    filter(top_category %in% c(target_categories, category_vector)) |>  # Filter to only relevant POIs
    mutate(category_indicator = if_else(top_category %in% target_categories, reference_name, category_name),
           category_indicator = factor(category_indicator, levels = c(reference_name, category_name)),
           age_group = factor(age_group, levels = c("under_18", "19_65", "65_plus")))  # Ensure Restaurant/Bar is the reference
  
  nb_model = glm.nb(visitor_count ~ age_group * category_indicator + offset(log(total_visitors)), data = df_model)

  print(summary(nb_model))
  
  return(nb_model)
}


# All groups v. restaurant and bar
nb_model_1 = run_nb_model(df_long, "Non-Restaurant", all_cat, "Restaurant/Bar", target_categories)

# Healthcare v. restaurant and bar
nb_model_2 = run_nb_model(df_long, "Healthcare", medical_services, "Restaurant/Bar", target_categories)

# Essential Services v. restaurant and bar
nb_model_3 = run_nb_model(df_long, "Essential Services", essential_services, "Restaurant/Bar", target_categories)

# Retail shopping v. restaurant and bar
nb_model_4 = run_nb_model(df_long, "Retail Shopping", retail_shopping, "Restaurant/Bar", target_categories)

# Entertainment/Recreation v. restaurant and bar
nb_model_5 = run_nb_model(df_long, "Entertainment/Recreation", entertainment_recreation, "Restaurant/Bar", target_categories)

# Personal Services v. restaurant and bar
nb_model_6 = run_nb_model(df_long, "Personal Services", personal_services, "Restaurant/Bar", target_categories)

#Hospitality/Lodging v. restaurant and bar
nb_model_7 = run_nb_model(df_long, "Hospitality/Lodging", hospitality_lodging, "Restaurant/Bar", target_categories)

#Office/Professional v. restaurant and bar
nb_model_8 = run_nb_model(df_long, "Office/Professional", office_professional, "Restaurant/Bar", target_categories)

```


```{r}
extract_nb_results = function(model, category_name) {
  results = broom.mixed::tidy(model) |> 
    filter(grepl("category_indicator", term)) |> 
    mutate(category = category_name) |> 
    relocate(category) |> 
    mutate(significance = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE ~ ""
    ))
  
  return(results)
}

nb_summary_table = bind_rows(
  extract_nb_results(nb_model_1, "Non-Restaurant"),
  extract_nb_results(nb_model_2, "Healthcare"),
  extract_nb_results(nb_model_3, "Essential Services"),
  extract_nb_results(nb_model_4, "Retail Shopping"),
  extract_nb_results(nb_model_5, "Entertainment/Recreation"),
  extract_nb_results(nb_model_6, "Personal Services"),
  extract_nb_results(nb_model_7, "Hospitality/Lodging"),
  extract_nb_results(nb_model_8, "Office/Professional")
)

knitr::kable(nb_summary_table)
```

### NB no interaction and offset - important
```{r}
run_nb_model = function(df, category_name, category_vector) {
  df_model = df |> 
    filter(top_category %in% category_vector) |>  # Filter to only relevant POIs
    mutate(
           age_group = factor(age_group, levels = c("under_18", "19_65", "65_plus")))  # Ensure age group ordering
  
  nb_model = glm.nb(visitor_count ~ age_group + offset(log(total_visitors)), data = df_model)

  print(summary(nb_model))
  
  return(nb_model)
}

# Run models for each POI type vs. Restaurant/Bar
nb_model_1 = run_nb_model(df_long, "Full", all_cat)
nb_model_2 = run_nb_model(df_long, "Healthcare", medical_services)
nb_model_3 = run_nb_model(df_long, "Essential Services", essential_services)
nb_model_4 = run_nb_model(df_long, "Retail Shopping", retail_shopping)
nb_model_5 = run_nb_model(df_long, "Entertainment/Recreation", entertainment_recreation)
nb_model_6 = run_nb_model(df_long, "Personal Services", personal_services)
nb_model_7 = run_nb_model(df_long, "Hospitality/Lodging", hospitality_lodging)
nb_model_8 = run_nb_model(df_long, "Office/Professional", office_professional)
nb_model_9 = run_nb_model(df_long, "Restaurant/Bar", target_categories)
```

```{r}
extract_nb_results = function(model, category_name) {
  results = broom.mixed::tidy(model) |> 
    mutate(significance = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE ~ ""
    ))
  
  return(results)
}

# Combine results from all models
nb_summary_table = bind_rows(
  extract_nb_results(nb_model_1, "Non-Restaurant"),
  extract_nb_results(nb_model_2, "Healthcare"),
  extract_nb_results(nb_model_3, "Essential Services"),
  extract_nb_results(nb_model_4, "Retail Shopping"),
  extract_nb_results(nb_model_5, "Entertainment/Recreation"),
  extract_nb_results(nb_model_6, "Personal Services"),
  extract_nb_results(nb_model_7, "Hospitality/Lodging"),
  extract_nb_results(nb_model_8, "Office/Professional"),
  extract_nb_results(nb_model_9, "Restaurant/Bar")
)

nb_summary_table = nb_summary_table |> 
  bind_cols(category = c("Full","Full","Full", "Healthcare", "Healthcare", "Healthcare", "Essential Services","Essential Services","Essential Services", "Retail Shopping","Retail Shopping","Retail Shopping", "Entertainment/Recreation","Entertainment/Recreation","Entertainment/Recreation", "Personal Services","Personal Services","Personal Services", "Hospitality/Lodging","Hospitality/Lodging","Hospitality/Lodging", "Office/Professional","Office/Professional","Office/Professional", "Restaurant/Bar","Restaurant/Bar","Restaurant/Bar")) |> 
  relocate(category)

# Display as a table
knitr::kable(nb_summary_table)

```
# Predictive model

```{r}
df_long$distance_km = distHaversine(
  matrix(c(df_long$vis_long, df_long$vis_lat), ncol = 2),
  matrix(c(df_long$poi_long, df_long$poi_lat), ncol = 2)
) / 1000  

set.seed(2025)  # Reproducibility

df_long = df_long |> drop_na()  # Drop missing values, this was breaking ridge

# Split dataset into training and testing
train_index = createDataPartition(df_long$visitor_count, p = 0.8, list = FALSE)
train_data = df_long[train_index, ]
test_data = df_long[-train_index, ]

```

Ridge regression, did lasso earlier but tuning parameters were shrinking too many variables to 0 effectively breaking the model. Ridge does not shrink coefficients to 0.
```{r, eval = FALSE}
# Filter for age group
train_under_18 = train_data |> filter(age_group == "under_18")
test_under_18 = test_data |> filter(age_group == "under_18")

X_train_under_18 = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = train_under_18)[, -1]
X_test_under_18 = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = test_under_18)[, -1]
y_train_under_18 = train_under_18$visitor_count
y_test_under_18 = test_under_18$visitor_count

ridge_cv_under_18 = cv.glmnet(X_train_under_18, y_train_under_18, alpha = 0, family = "poisson")
best_lambda_ridge_under_18 = ridge_cv_under_18$lambda.min
ridge_under_18 = glmnet(X_train_under_18, y_train_under_18, alpha = 0, family = "poisson", lambda = best_lambda_ridge_under_18)

pred_ridge_under_18 = predict(ridge_under_18, X_test_under_18, type = "response")

rmse_ridge_under_18 = sqrt(mean((y_test_under_18 - pred_ridge_under_18)^2))
cat("Ridge RMSE for Under 18:", rmse_ridge_under_18, "\n")


### Ridge for 19-65
train_19_65 = train_data |> filter(age_group == "19_65")
test_19_65 = test_data |> filter(age_group == "19_65")

X_train_19_65 = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = train_19_65)[, -1]
X_test_19_65 = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = test_19_65)[, -1]
y_train_19_65 = train_19_65$visitor_count
y_test_19_65 = test_19_65$visitor_count

ridge_cv_19_65 = cv.glmnet(X_train_19_65, y_train_19_65, alpha = 0, family = "poisson")
best_lambda_ridge_19_65 = ridge_cv_19_65$lambda.min
ridge_19_65 = glmnet(X_train_19_65, y_train_19_65, alpha = 0, family = "poisson", lambda = best_lambda_ridge_19_65)

pred_ridge_19_65 = predict(ridge_19_65, X_test_19_65, type = "response")
rmse_ridge_19_65 = sqrt(mean((y_test_19_65 - pred_ridge_19_65)^2))
cat("Ridge RMSE for 19-65:", rmse_ridge_19_65, "\n")

### Ridge for 65+
train_65_plus = train_data |> filter(age_group == "65_plus")
test_65_plus = test_data |> filter(age_group == "65_plus")

X_train_65_plus = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = train_65_plus)[, -1]
X_test_65_plus = model.matrix(visitor_count ~ top_category + total_visitors + distance_km, data = test_65_plus)[, -1]
y_train_65_plus = train_65_plus$visitor_count
y_test_65_plus = test_65_plus$visitor_count

ridge_cv_65_plus = cv.glmnet(X_train_65_plus, y_train_65_plus, alpha = 0, family = "poisson")
best_lambda_ridge_65_plus = ridge_cv_65_plus$lambda.min
ridge_65_plus = glmnet(X_train_65_plus, y_train_65_plus, alpha = 0, family = "poisson", lambda = best_lambda_ridge_65_plus)

pred_ridge_65_plus = predict(ridge_65_plus, X_test_65_plus, type = "response")
rmse_ridge_65_plus = sqrt(mean((y_test_65_plus - pred_ridge_65_plus)^2))
cat("Ridge RMSE for 65+:", rmse_ridge_65_plus, "\n")


# Extract and display non-zero coefficients for Under 18
cat("\nSelected Variables for Under 18:\n")
print(ridge_coefs_under_18_df |> filter(coefficient != 0))

cat("\nSelected Variables for 19-65:\n")
print(ridge_coefs_19_65_df |> filter(coefficient != 0))

cat("\nSelected Variables for 65+:\n")
print(ridge_coefs_65_plus_df |> filter(coefficient != 0))

```




