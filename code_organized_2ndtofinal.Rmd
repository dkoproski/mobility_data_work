---
title: "Code - A bit more organized"
author: "Dylan Koproski"
date: "2025-01-28"
output: pdf_document
---
# Libraries
```{r}
library(tidyverse)
library(jsonlite)
library(readxl)
library(rsample)
library(caret)
library(VGAM)
library(COMPoissonReg)
library(pscl)
library(lme4)
library(maps)
library(zipcodeR)
```


# Preprocessing

```{r}
# Load data
df_visitor = read_csv("mobility.csv")
df_census = read_csv("tract_census.csv", skip = 1) |> 
  janitor::clean_names()
df_tract_zip = read_excel("tract_zip.xlsx")



# Temporary restriction to NYC
state_county_code_str = c(36005, 36047, 36061, 36081, 36085)

# Process visitor data - none missing
filtered_df_visitor = df_visitor |> 
  mutate(first_five_digits = substr(poi_cbg, 1, 5)) |>
  filter(first_five_digits %in% state_county_code_str) |> 
  # Dropping missing values for home cbg
  filter(!is.na(visitor_home_aggregation)) |> 
  mutate(identifier = row_number()) |> 
  mutate(poi_zip = postal_code) |> 
  mutate(visitor_home_aggregation = map(visitor_home_aggregation, ~fromJSON(as.character(.)))) |> 
  select(location_name, date_range_start, date_range_end, visitor_home_aggregation, top_category, identifier, poi_cbg, poi_zip, latitude, longitude) |>
  unnest_longer(visitor_home_aggregation) |>
  rename(visitor_census_tract = visitor_home_aggregation_id, visitors = visitor_home_aggregation) |> 
  mutate(visitors = if_else(visitors == 4, 3, visitors)) |> 
  mutate(poi_lat = latitude,
         poi_long = longitude)

# Census data processing
df_census = df_census |> 
  rowwise() |> 
  mutate(cbg = str_sub(geography, -11)) |> 
#873 locations have an estimated 0 people, we should exclude these.
  filter(estimate_total_total_population > 0)

# Age group proportions in census data, separate into 3 age groups
filtered_df_census_totals = 
  df_census |> 
  rowwise() |> 
  select(estimate_total_total_population, cbg, geographic_area_name, starts_with("estimate")) |> 
  mutate(
    total_under_18 = sum(estimate_total_total_population_age_under_5_years,
                         estimate_total_total_population_age_5_to_9_years,
                         estimate_total_total_population_age_10_to_14_years,
                         estimate_total_total_population_age_15_to_19_years) / estimate_total_total_population,
    
    total_19_65 = sum(estimate_total_total_population_age_20_to_24_years,
                      estimate_total_total_population_age_25_to_29_years,
                      estimate_total_total_population_age_30_to_34_years,
                      estimate_total_total_population_age_35_to_39_years,
                      estimate_total_total_population_age_40_to_44_years,
                      estimate_total_total_population_age_45_to_49_years,
                      estimate_total_total_population_age_50_to_54_years,
                      estimate_total_total_population_age_55_to_59_years,
                      estimate_total_total_population_age_60_to_64_years,
                      estimate_total_total_population_age_65_to_69_years) / estimate_total_total_population,

    total_65_plus = sum(estimate_total_total_population_age_70_to_74_years,
                        estimate_total_total_population_age_75_to_79_years,
                        estimate_total_total_population_age_80_to_84_years,
                        estimate_total_total_population_age_85_years_and_over) / estimate_total_total_population
  ) |> 
  rename("total" = estimate_total_total_population) |> 
  select(cbg, geographic_area_name, total, total_under_18, total_19_65, total_65_plus)

# Define primary ZIP code per census tract
primary_tract_zip = df_tract_zip |> 
  group_by(tract) |> 
  summarize(zip = min(zip))  # Selects the minimum ZIP as primary for simplicity

# Merge filtered_df_census_totals with filtered_df_visitor
merged_df = filtered_df_visitor |> 
  inner_join(filtered_df_census_totals, by = c("visitor_census_tract" = "cbg")) |> 
  mutate(
    visitors_under_18 = visitors * total_under_18,
    visitors_19_65 = visitors * total_19_65,
    visitors_65_plus = visitors * total_65_plus
  ) 

# Map primary ZIP codes by merging with primary_tract_zip on the census tract
final_df = merged_df |> 
  left_join(primary_tract_zip, by = c("visitor_census_tract" = "tract")) |> 
  select(location_name, date_range_start, date_range_end, top_category, 
         identifier, poi_cbg, poi_zip, visitors, visitors_under_18, 
         visitors_19_65, visitors_65_plus, zip, poi_long, poi_lat) |> 
  mutate(visitor_zip = zip)

vis_zip_lat_long = geocode_zip(final_df$visitor_zip)

final_df = final_df |> 
  left_join(vis_zip_lat_long, by = join_by(visitor_zip == zipcode)) |> 
  mutate(vis_lat = lat,
         vis_long = lng) |> 
  select(-lat, -lng)

# Rounding, can be adjusted at will
final_df = final_df |> 
  mutate(visitors_under_18 = ceiling(visitors_under_18),
         visitors_19_65 = ceiling(visitors_19_65),
         visitors_65_plus = ceiling(visitors_65_plus)) |> 
  mutate(total_visitors = visitors_under_18 + visitors_19_65 + visitors_65_plus)

# There are 2 rows in the above data that have missing values, the visitor zip is missing. We should figure out how to handle this specifically 

# Long dataframe for modelling purposes
df_long = final_df |> 
  pivot_longer(
    cols = starts_with("visitors_"),
    names_to = "age_group",
    names_prefix = "visitors_",
    values_to = "visitor_count"
  ) |> 
  mutate(top_category = factor(top_category),
         age_group = factor(age_group, levels = c("under_18", "19_65", "65_plus")))

# Data quality looks good, 2 missing zip codes may need to be handled, but data is large enough maybe dropping them won't hurt (n = 21895 vs. n = 21893)
```


# Exploratory Data Analysis (EDA)

## Zip Code Flow Matrix
```{r}
# Remove rows with NA in visitor_zip or poi_zip
zip_matrix = final_df |> 
  filter(!is.na(visitor_zip) & !is.na(poi_zip)) |> 
  group_by(visitor_zip, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) |> 
  pivot_wider(names_from = poi_zip, values_from = total_visitors, values_fill = 0)

# Convert to matrix and plot
zip_matrix_plot = zip_matrix |> 
  column_to_rownames("visitor_zip") |> 
  as.matrix() |> 
  heatmap(
    col = colorRampPalette(c("white", "red"))(100),
    scale = "none",
    main = "Zip-to-Zip Visitor Flow",
    xlab = "Destination ZIP (To)",
    ylab = "Origin ZIP (From)"
  )
```

## State to Destination ZIP in NYC
```{r}
final_df_with_state = final_df |> 
  left_join(df_tract_zip, by = c("visitor_zip" = "zip")) |> 
  select(!zip) |> 
  rename(visitor_state = usps_zip_pref_state)

state_zip_matrix = final_df_with_state |> 
  group_by(visitor_state, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 

ggplot(state_zip_matrix, aes(x = poi_zip, y = visitor_state, fill = total_visitors)) + 
  geom_tile() + 
  scale_fill_viridis_c() + 
  labs(
    title = "State-to-NYC ZIP Code Visitor Flow",
    x = "Destination ZIP (NYC)",
    y = "Origin State"
  ) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

# Visualizations

## Heatmap - no basemap, just blobs. This can be improved
```{r}
nyc_zip_visitors = final_df |> 
  group_by(poi_long, poi_lat) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 

usa = map_data("state")

ggplot(nyc_zip_visitors, aes(x = poi_long, y = poi_lat)) +
  stat_density_2d(aes(fill = after_stat(level)), geom = "polygon", color = NA) +
  scale_fill_viridis_c() +
  labs(
    title = "Heatmap of NYC POIs by Visitor Counts",
    x = "Longitude", 
    y = "Latitude"
  ) +
  theme_minimal()
```

## Flow map - work in progress

```{r}
ggplot() +
  geom_polygon(data = usa,
               aes(x = long, y = lat),
               fill = "white", color = "gray50") +
  
  geom_segment(data = df_long,
               aes(x = vis_long, y = vis_lat,
                   xend = poi_long, yend = poi_lat,
                   color = visitors),
               alpha = 0.6, linewidth = 1) +
  scale_color_gradient(low = "lightblue", high = "darkred") +
  coord_map() 
  theme_minimal() +
  labs(color = "Volume of Visits",
       title = "Zip Code to Zip Code Visits")

```


# Modeling

## Data Preparation for Modeling
```{r}
# Filter and prepare data for modeling
# Adjust target based on POI types of interest
# See levels(df_long$top_category) for poi names
target = c("Drinking Places (Alcoholic Beverages)", "Restaurants and Other Eating Places")

df_long_model_filtered = df_long |> 
  filter(top_category %in% target)

set.seed(100)
data_split = initial_split(df_long_model_filtered, prop = 0.80)
df_train = training(data_split)
df_test = testing(data_split)

train_control = trainControl(method = "cv", number = 10)
```

## Model fitting

```{r}
# Fit Poisson model
poisson_model = glm(visitor_count ~ age_group, family = poisson(link = "log"), data = df_train)
summary(poisson_model)

# Predictions and performance metrics
poisson_predictions = predict(poisson_model, newdata = df_test, type = "response")
rmse_poisson = sqrt(mean((df_test$visitor_count - poisson_predictions)^2))
mae_poisson = mean(abs(df_test$visitor_count - poisson_predictions))

cat("Poisson RMSE:", round(rmse_poisson, 2), "\n")
cat("Poisson MAE:", round(mae_poisson, 2), "\n")

# Overdispersion check
dispersion_parameter = sum(residuals(poisson_model, type = "pearson")^2) / poisson_model$df.residual
dev_ratio = poisson_model$deviance / poisson_model$df.residual
cat("Dispersion Parameter:", round(dispersion_parameter, 2), "\n")
cat("Deviance/DF Ratio:", round(dev_ratio, 2), "\n")

# Fit other generalized models
models = list(
  poisson_model = glm(visitor_count ~ age_group, family = poisson(link = "log"), data = df_train),
  GenPoisson0 = vglm(visitor_count ~ age_group, family = "genpoisson0", data = df_train),
  GenPoisson1 = vglm(visitor_count ~ age_group, family = "genpoisson1", data = df_train),
  GenPoisson2 = vglm(visitor_count ~ age_group, family = "genpoisson2", data = df_train),
  COMPoisson = glm.cmp(visitor_count ~ age_group, data = df_train),
  ZeroInflated = zeroinfl(visitor_count ~ age_group | age_group, data = df_train, dist = "poisson"),
  mixed_poisson_model = glmer(visitor_count ~ age_group + (1 | poi_zip), data = df_long_model_filtered, family = poisson(link = "log"))
)
#Gen poissons, zero inflated produce warnings. good news is they perform poorly so doesn't matter anyways. com is best

# Evaluate models
performance_metrics = lapply(models, function(model) {
  predictions = predict(model, newdata = df_test, type = "response")
  rmse = sqrt(mean((df_test$visitor_count - predictions)^2))
  mae = mean(abs(df_test$visitor_count - predictions))
  aic = tryCatch(AIC(model), error = function(e) NA)
  bic = tryCatch(BIC(model), error = function(e) NA)
  return(c(RMSE = rmse, MAE = mae, AIC = aic, BIC = bic))
})

# Convert to data frame
performance_table = do.call(rbind, performance_metrics)
rownames(performance_table) = names(models)
colnames(performance_table) = c("RMSE", "MAE", "AIC", "BIC")
print(performance_table)

# Visualization of Actual vs. Predicted (GenPoisson2 example)
COMPoisson_predictions = predict(models$COMPoisson, newdata = df_test, type = "response")
plot_data = data.frame(Actual = df_test$visitor_count, Predicted = COMPoisson_predictions, Age_Group = df_test$age_group)

ggplot(plot_data, aes(x = Actual, y = Predicted, color = Age_Group)) +
  geom_jitter(width = 0.2, height = 0.2, alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(
    title = "GenPoisson2 Model: Actual vs. Predicted Visitor Counts",
    x = "Actual Visitor Count",
    y = "Predicted Visitor Count",
    color = "Age Group"
  ) +
  theme_minimal()
```

# Additional Visualizations

## Bar Plot
```{r}
age_group_summary = df_long_model_filtered |>
  group_by(age_group, top_category) |>
  summarize(total_visitors = sum(visitor_count), .groups = "drop")

ggplot(age_group_summary, aes(x = age_group, y = total_visitors, fill = top_category)) +
  geom_col(position = "dodge") +
  labs(
    title = "Visitor Counts by Age Group and Location Type",
    x = "Age Group",
    y = "Total Visitors",
    fill = "Location Type"
  ) +
  theme_minimal()
```

## Pie chart (alternative to above)

```{r}
age_group_proportions = df_long_model_filtered |>
  group_by(age_group) |>
  summarize(total_visitors = sum(visitor_count), .groups = "drop") |>
  mutate(proportion = total_visitors / sum(total_visitors))

ggplot(age_group_proportions, aes(x = "", y = proportion, fill = age_group)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(
    title = "Proportion of Visitors by Age Group",
    fill = "Age Group"
  ) +
  theme_void()

```

## Density Plot

```{r}
ggplot(df_long_model_filtered, aes(x = visitor_count, fill = age_group)) +
  geom_density(alpha = 0.6) +
  labs(
    title = "Density of Visitor Counts by Age Group",
    x = "Visitor Count",
    y = "Density",
    fill = "Age Group"
  ) +
  theme_minimal()
```