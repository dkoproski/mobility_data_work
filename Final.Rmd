---
title: "Final"
author: "Dylan Koproski & Dylan Morgan"
date: "2024-10-29"
output: pdf_document
---

* Verify that the zip matching worked properly, and check for missing zip codes

```{r}
library(tidyverse)
library(jsonlite)
library(readxl)

# Load data
df_visitor = read_csv("mobility.csv")
df_census = read_csv("tract_census.csv", skip = 1) |> 
  janitor::clean_names()
df_tract_zip = read_excel("tract_zip.xlsx")

# Temporary restriction to NYC
state_county_code_str = c(36005, 36047, 36061, 36081, 36085)

# Process visitor data
filtered_df_visitor = df_visitor |> 
  mutate(first_five_digits = substr(poi_cbg, 1, 5)) |>
  filter(first_five_digits %in% state_county_code_str) |> 
  filter(!is.na(visitor_home_aggregation)) |> 
  mutate(identifier = row_number()) |> 
  mutate(poi_zip = postal_code) |> 
  mutate(visitor_home_aggregation = map(visitor_home_aggregation, ~fromJSON(as.character(.)))) |> 
  select(location_name, date_range_start, date_range_end, visitor_home_aggregation, top_category, identifier, poi_cbg, poi_zip, latitude, longitude) |>
  unnest_longer(visitor_home_aggregation) |>
  rename(visitor_census_tract = visitor_home_aggregation_id, visitors = visitor_home_aggregation) |> 
  mutate(visitors = if_else(visitors == 4, 3, visitors)) 

# Census data processing
df_census = df_census |> 
  rowwise() |> 
  mutate(cbg = str_sub(geography, -11))

# Age group proportions in census data
filtered_df_census_totals = 
  df_census |> 
  rowwise() |> 
  select(estimate_total_total_population, cbg, geographic_area_name, starts_with("estimate")) |> 
  mutate(
    total_under_18 = sum(estimate_total_total_population_age_under_5_years,
                         estimate_total_total_population_age_5_to_9_years,
                         estimate_total_total_population_age_10_to_14_years,
                         estimate_total_total_population_age_15_to_19_years) / estimate_total_total_population,
    
    total_19_65 = sum(estimate_total_total_population_age_20_to_24_years,
                      estimate_total_total_population_age_25_to_29_years,
                      estimate_total_total_population_age_30_to_34_years,
                      estimate_total_total_population_age_35_to_39_years,
                      estimate_total_total_population_age_40_to_44_years,
                      estimate_total_total_population_age_45_to_49_years,
                      estimate_total_total_population_age_50_to_54_years,
                      estimate_total_total_population_age_55_to_59_years,
                      estimate_total_total_population_age_60_to_64_years,
                      estimate_total_total_population_age_65_to_69_years) / estimate_total_total_population,

    total_65_plus = sum(estimate_total_total_population_age_70_to_74_years,
                        estimate_total_total_population_age_75_to_79_years,
                        estimate_total_total_population_age_80_to_84_years,
                        estimate_total_total_population_age_85_years_and_over) / estimate_total_total_population
  ) |> 
  rename("total" = estimate_total_total_population) |> 
  select(cbg, geographic_area_name, total, total_under_18, total_19_65, total_65_plus)

# Define primary ZIP code per census tract
primary_tract_zip = df_tract_zip |> 
  group_by(tract) |> 
  summarize(zip = min(zip))  # Selects the minimum ZIP as primary for simplicity

# Merge filtered_df_census_totals with filtered_df_visitor
merged_df = filtered_df_visitor |> 
  inner_join(filtered_df_census_totals, by = c("visitor_census_tract" = "cbg")) |> 
  mutate(
    visitors_under_18 = visitors * total_under_18,
    visitors_19_65 = visitors * total_19_65,
    visitors_65_plus = visitors * total_65_plus
  ) 

# Map primary ZIP codes by merging with primary_tract_zip on the census tract
final_df = merged_df |> 
  left_join(primary_tract_zip, by = c("visitor_census_tract" = "tract")) |> 
  select(location_name, date_range_start, date_range_end, top_category, 
         identifier, poi_cbg, poi_zip, visitors, visitors_under_18, 
         visitors_19_65, visitors_65_plus, zip, longitude, latitude) |> 
  mutate(visitor_zip = zip)

# Rounding, can be adjusted at will
final_df = final_df |> 
  mutate(visitors_under_18 = ceiling(visitors_under_18),
         visitors_19_65 = ceiling(visitors_19_65),
         visitors_65_plus = ceiling(visitors_65_plus)) |> 
  mutate(total_visitors = visitors_under_18 + visitors_19_65 + visitors_65_plus)

# Long dataframe for modelling purposes
df_long = final_df |> 
  pivot_longer(
    cols = starts_with("visitors_"),
    names_to = "age_group",
    names_prefix = "visitors_",
    values_to = "visitor_count"
  ) |> 
  mutate(top_category = factor(top_category),
         age_group = factor(age_group, levels = c("under_18", "19_65", "65_plus")))

```

# Visualizing the matrix of zip code - zip code

## Preliminary matrix, this guy looks bad

```{r}
# Remove rows with NA in visitor_zip or poi_zip
zip_matrix = final_df |> 
  filter(!is.na(visitor_zip) & !is.na(poi_zip)) |> 
  group_by(visitor_zip, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) |> 
  pivot_wider(names_from = poi_zip, values_from = total_visitors, values_fill = 0)

# Convert to matrix and plot
zip_matrix_plot = zip_matrix |> 
  column_to_rownames("visitor_zip") |> 
  as.matrix() |> 
  heatmap(
    col = colorRampPalette(c("white", "red"))(100),
    scale = "none",
    main = "Zip-to-Zip Visitor Flow",
    xlab = "Destination ZIP (To)",
    ylab = "Origin ZIP (From)"
  )
```

## Tile graph of state to destination zip in NYC, a little better, at least we can see that the data isn't incredibly sparse

``` {r}
## It is so wacky to present this in a matrix, we aren't doing that

final_df_with_state = final_df |> 
  left_join(df_tract_zip, by = c("visitor_zip" = "zip")) |> 
  rename(visitor_state = usps_zip_pref_state)
## later things are dependent on this
state_zip_matrix = final_df_with_state |> 
  group_by(visitor_state, poi_zip) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 

ggplot(state_zip_matrix, aes(x = poi_zip, y = visitor_state, fill = total_visitors)) + 
  geom_tile() + 
  scale_fill_viridis_c() + 
  labs(
    title = "State-to-NYC ZIP Code Visitor Flow",
    x = "Destination ZIP (NYC)",
    y = "Origin State"
  ) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

### Mapping
To do on here:
* Get an NYC map to underlay
* Maybe use some better colors
```{r}
library(ggmap)

nyc_zip_visitors = final_df |> 
  group_by(longitude, latitude) |> 
  summarize(total_visitors = sum(visitors, na.rm = TRUE)) 

ggplot(nyc_zip_visitors, aes(x = longitude, y = latitude)) +
  stat_density_2d(aes(fill = ..level..), geom = "polygon", color = NA) +
  scale_fill_viridis_c() +
  labs(
    title = "Heatmap of NYC POIs by Visitor Counts",
    x = "Longitude", 
    y = "Latitude"
  ) +
  theme_minimal()
```

```{r}
library(ggplot2)
library(ggmap)

# Get an OpenStreetMap base map using get_stadiamap
osm_map <- get_stadiamap(
  bbox = c(left = min(nyc_zip_visitors$longitude), 
           bottom = min(nyc_zip_visitors$latitude), 
           right = max(nyc_zip_visitors$longitude), 
           top = max(nyc_zip_visitors$latitude)),
  zoom = 12,
  maptype = "alidade_smooth" # Options: "alidade_smooth", "alidade_smooth_dark", "outdoors", etc.
)

# Plot the heatmap on top of the OpenStreetMap base map
ggmap(osm_map) +
  stat_density_2d(data = nyc_zip_visitors, 
                  aes(x = longitude, y = latitude, fill = ..level..), 
                  geom = "polygon", alpha = 0.6) +
  scale_fill_viridis_c() +
  labs(
    title = "Heatmap of NYC POIs by Visitor Counts",
    x = "Longitude", 
    y = "Latitude"
  ) +
  theme_minimal()

```


# Modelling 

## Preprocess

```{r}
# do this BEFORE SPLITTING!!!
df_long_model_filtered = df_long |> 
  filter(top_category %in% c('Drinking Places (Alcoholic Beverages)', 'Restaurants and Other Eating Places')) |> 
  drop_na()

library(rsample) # for data splitting
library(caret) # for modelling with cv
library(VGAM)
library(COMPoissonReg)
library(pscl)
set.seed(100)
data_split = initial_split(df_long_model_filtered, prop = 0.80)
df_train = training(data_split)
df_test = testing(data_split)

# define control
train_control = trainControl(method = "cv", number = 10)
```

## Poisson model

```{r}
set.seed(100)
poisson_model = glm(visitor_count ~ age_group, 
                     family = poisson(link = "log"), 
                     data = df_train)

s = summary(poisson_model)

predictions = predict(poisson_model, newdata = df_test, type = "response")

rmse = sqrt(mean((df_test$visitor_count - predictions)^2))
print(paste("RMSE:", round(rmse, 2)))


mae = mean(abs(df_test$visitor_count - predictions))
print(paste("MAE:", round(mae, 2)))

# Create a data frame for plotting
plot_data = data.frame(
  Actual = df_test$visitor_count,
  Predicted = predictions,
  Age_Group = df_test$age_group
)

# Checking for overdispersion
dispersion_parameter = sum(residuals(poisson_model, type = "pearson")^2) / poisson_model$df.residual
print(paste("Dispersion parameter:", round(dispersion_parameter, 2)))

deviance_ratio = poisson_model$deviance / poisson_model$df.residual
print(paste("Ratio of deviance to degrees of freedom:", round(deviance_ratio, 2)))


pearson_resid = residuals(poisson_model, type = "pearson")

# Plot residuals vs. fitted values
plot(fitted(poisson_model), pearson_resid,
     xlab = "Fitted Values",
     ylab = "Pearson Residuals",
     main = "Residuals vs. Fitted Values")
abline(h = 0, col = "red", lty = 2)

# Clustering, indicative of underdispersion

# Fit the Generalized Poisson model
genpois0_model = vglm(visitor_count ~ age_group, 
                      family = "genpoisson0", 
                      data = df_train)

# Summary of the model
summary(genpois0_model)


# Fit the Generalized Poisson model
genpois1_model = vglm(visitor_count ~ age_group, 
                      family = "genpoisson1", 
                      data = df_train)

# Summary of the model
summary(genpois1_model)

# Fit the Generalized Poisson model
genpois2_model = vglm(visitor_count ~ age_group, 
                      family = "genpoisson2", 
                      data = df_train)

# Summary of the model
summary(genpois2_model)

compois_model =
  glm.cmp(visitor_count ~ age_group, 
          data = df_train)

summary(compois_model)

# Zero inflated model
zip_model =
  zeroinfl(visitor_count ~ age_group | age_group, 
                      data = df_train, 
                      dist = "poisson")

# Summary of the model
summary(zip_model)

model_list = list(
  list(name = "Poisson", model = poisson_model),
  list(name = "GenPoisson0", model = genpois0_model),
  list(name = "GenPoisson1", model = genpois1_model),
  list(name = "GenPoisson2", model = genpois2_model),
  list(name = "COM-Poisson", model = compois_model),
  list(name = "Zero-Inflated Poisson", model = zip_model)
)

# Initialize vectors to store performance metrics
model_names = c()
rmse_values = c()
mae_values = c()
aic_values = c()
bic_values = c()

# Loop over each model to compute metrics
for (model_info in model_list) {
  model_name = model_info$name
  model = model_info$model
  model_names = c(model_names, model_name)
  
  # Generate predictions on the test data
  if (model_name == "COM-Poisson") {
    # For COM-Poisson model
    predictions = predict(model, newdata = df_test, type = "response")
  } else {
    # For other models
    predictions = predict(model, newdata = df_test, type = "response")
  }
  
  # Calculate RMSE and MAE
  rmse = sqrt(mean((df_test$visitor_count - predictions)^2))
  mae = mean(abs(df_test$visitor_count - predictions))
  rmse_values = c(rmse_values, rmse)
  mae_values = c(mae_values, mae)
  
  # Calculate AIC and BIC if available
  if (model_name == "COM-Poisson") {
    # AIC and BIC are not directly available for COM-Poisson model
    aic_values = c(aic_values, NA)
    bic_values = c(bic_values, NA)
  } else if (inherits(model, "vglm")) {
    # For VGAM models (Generalized Poisson), use VGAM methods
    aic = VGAM::AICvlm(model)
    bic = VGAM::BICvlm(model)
    aic_values = c(aic_values, aic)
    bic_values = c(bic_values, bic)
  } else {
    # For other models, use standard AIC and BIC functions
    aic = AIC(model)
    bic = BIC(model)
    aic_values = c(aic_values, aic)
    bic_values = c(bic_values, bic)
  }
}

# Create a data frame with performance metrics
performance_table = data.frame(
  Model = model_names,
  RMSE = round(rmse_values, 2),
  MAE = round(mae_values, 2),
  AIC = round(aic_values, 2),
  BIC = round(bic_values, 2)
)

# Display the performance table using kable()
knitr::kable(performance_table, caption = "Model Performance Metrics")

predictions = predict(genpois2_model, newdata = df_test, type = "response")

# Create a data frame with actual and predicted values
plot_data = data.frame(
  Actual = df_test$visitor_count,
  Predicted = predictions,
  Age_Group = df_test$age_group
)

# Scatter plot of actual vs. predicted counts
ggplot(plot_data, aes(x = Actual, y = Predicted, color = Age_Group)) +
  geom_jitter(width = 0.2, height = 0.2, alpha = 0.6) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  labs(title = "GenPoisson2 Model: Actual vs. Predicted Visitor Counts",
       x = "Actual Visitor Count",
       y = "Predicted Visitor Count",
       color = "Age Group") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```


